Traceback (most recent call last):
  File "C:\Users\acer\AppData\Roaming\Python\Python312\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\acer\AppData\Roaming\Python\Python312\site-packages\nbclient\client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\acer\AppData\Roaming\Python\Python312\site-packages\jupyter_core\utils\__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python312\Lib\asyncio\base_events.py", line 685, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\acer\AppData\Roaming\Python\Python312\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\Users\acer\AppData\Roaming\Python\Python312\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\acer\AppData\Roaming\Python\Python312\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris
from scipy.spatial.distance import cdist
from sklearn.metrics import silhouette_score

# Load iris dataset
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df.columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

# Tambahkan label asli (Target)
df['Target'] = iris.target

# Normalisasi data
scaler = StandardScaler()
features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
df[features] = scaler.fit_transform(df[features])

# Tentukan centroid awal manual (misal indeks 0 dan 50 untuk 2 cluster)
centroid_indices = [0, 50]
centroids = df.loc[centroid_indices, features].values

print("\nCentroid Awal:")
for i, idx in enumerate(centroid_indices, start=1):
    print(f"Centroid {i} (data ke-{idx}): {centroids[i-1]}")

max_iter = 100
tolerance = 1e-6

for iteration in range(1, max_iter + 1):
    distances = cdist(df[features].values, centroids, metric='euclidean')
    df['Cluster_Diikuti'] = np.argmin(distances, axis=1)
    new_centroids = np.array([df.loc[df['Cluster_Diikuti'] == k, features].mean().values for k in range(len(centroids))])
    centroid_shift = np.linalg.norm(new_centroids - centroids)
    print(f"Iterasi ke-{iteration}: Perubahan centroid = {centroid_shift:.8f}")
    centroids = new_centroids
    if centroid_shift < tolerance:
        print("Centroid sudah konvergen.")
        break

print("\nCentroid Akhir:")
for i, centroid in enumerate(centroids, start=1):
    print(f"Centroid {i}: {centroid}")

# Mapping cluster ke label asli berdasarkan mayoritas label dalam cluster
mapped_labels = {}
for cluster_label, group in df.groupby('Cluster_Diikuti'):
    most_common_label = group['Target'].mode()[0]
    mapped_labels[cluster_label] = most_common_label

# Buat kolom PredictedLabel hasil mapping
df['PredictedLabel'] = df['Cluster_Diikuti'].map(mapped_labels)

# Cek benar atau salah
df['IsCorrect'] = (df['PredictedLabel'] == df['Target'])

# Tampilkan jumlah benar dan salah tiap cluster
print("\nJumlah Benar dan Salah Tiap Cluster:")
for cluster_label, group in df.groupby('Cluster_Diikuti'):
    benar = group['IsCorrect'].sum()
    salah = len(group) - benar
    print(f"Cluster {cluster_label}: Total={len(group)}, Benar={benar}, Salah={salah}")

# Hitung dan tampilkan inertia (jumlah kuadrat jarak data ke centroidnya)
inertia = 0
for i in range(len(centroids)):
    cluster_points = df[df['Cluster_Diikuti'] == i][features].values
    centroid = centroids[i]
    inertia += np.sum(np.linalg.norm(cluster_points - centroid, axis=1)**2)
print(f"\nInertia: {inertia:.4f}")

# Hitung silhouette score
sil_score = silhouette_score(df[features], df['Cluster_Diikuti'])
print(f"Silhouette Score: {sil_score:.4f}")

# Tampilkan akurasi keseluruhan
total_benar = df['IsCorrect'].sum()
total_data = len(df)
akurasi = total_benar / total_data * 100
print(f"\nAkurasi keseluruhan: {akurasi:.2f}%")

# Tampilkan semua data lengkap dengan nomor urut
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df_reset = df.reset_index(drop=True)
df_reset.index += 1  # nomor urut mulai dari 1

print("\nData Lengkap dengan Nomor Urut:")
print(df_reset[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Target', 'Cluster_Diikuti', 'PredictedLabel', 'IsCorrect']].to_string(index=True))

------------------


[1;31m------------------------------------------------------------[0m
[1;31mModuleNotFoundError[0m        Traceback (most recent call last)
Cell [1;32mIn[1], line 1[0m
[1;32m----> 1[0m [38;5;28;01mimport[39;00m[38;5;250m [39m[38;5;21;01mpandas[39;00m[38;5;250m [39m[38;5;28;01mas[39;00m[38;5;250m [39m[38;5;21;01mpd[39;00m
[0;32m      2[0m [38;5;28;01mimport[39;00m[38;5;250m [39m[38;5;21;01mnumpy[39;00m[38;5;250m [39m[38;5;28;01mas[39;00m[38;5;250m [39m[38;5;21;01mnp[39;00m
[0;32m      3[0m [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;21;01msklearn[39;00m[38;5;21;01m.[39;00m[38;5;21;01mpreprocessing[39;00m[38;5;250m [39m[38;5;28;01mimport[39;00m StandardScaler

[1;31mModuleNotFoundError[0m: No module named 'pandas'

